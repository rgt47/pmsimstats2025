---
title: "Comparing Classic Crossover Trials and Aggregated N-of-1 Trials"
subtitle: "A Methodological White Paper"
author: ""
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 7,
  fig.height = 5
)
```

# Abstract

Classic crossover trials and aggregated N-of-1 trials share surface similarities, including repeated administration of treatments within individuals and frequent use of mixed-effects models. However, despite this overlap, the designs differ fundamentally in structure, inferential goals, estimands, replication, and the appropriate specification of linear mixed-effects models. This white paper expands on the conceptual and statistical distinctions between classic crossover designs and aggregated N-of-1 designs, includes narrative citations throughout, and provides a worked example involving a hypothetical PTSD trial using the Clinician-Administered PTSD Scale (CAPS) to illustrate how either design might be implemented.

# Introduction

Repeated-treatment clinical trial designs reduce between-person variability by allowing each participant to serve as their own control. The best-known version of this approach is the classic crossover trial, widely used in chronic and stable conditions (Jones & Kenward, 2014). In contrast, N-of-1 trials, especially aggregated N-of-1 trials, are designed to evaluate individual-level responses and heterogeneity (Lillie et al., 2011; Guyatt et al., 2000). Despite frequent use of mixed-effects models in both designs, the correct statistical model depends on the inferential target and replication structure (Senn, 2002).

This white paper expands on how these two designs differ and why mixed-model analyses cannot be identical, even though they share an analytical framework. It concludes with an applied example involving a PTSD treatment trial using CAPS scores.

# Background

## Classic Crossover Trials

Classic crossover trials are structured in a small number of periods (typically 2–4), with treatment sequences such as AB/BA or ABA/BAB (Araujo & Julious, 2014). Their primary purpose is to estimate a population average treatment effect while controlling for period and sequence effects (Mills et al., 2009). These designs assume relative stability over time, limited carryover, and generally homogeneous treatment effects across participants (Senn, 2002). A 3-period design (ABA/BAB) provides each participant with 3 treatment exposures, offering slightly more within-person replication than a 2-period design while remaining practical.

## N-of-1 Trials

N-of-1 trials constitute repeated, randomized, within-person experiments using alternating treatment periods (Guyatt et al., 2000). They provide dense, within-person data suitable for estimating individual treatment effects, with multiple treatment exposures (e.g., 3 cycles of active and placebo, yielding 3 on-treatment and 3 off-treatment periods).

## Aggregated N-of-1 Trials

Aggregated N-of-1 studies combine individual trials through hierarchical modeling to estimate both person-specific and population-level effects (Zucker et al., 2010; Punja et al., 2016). They explicitly target treatment-effect heterogeneity and leverage partial pooling (Deaton & Cartwright, 2018).

## Hybrid Designs

Between classic crossover and full N-of-1 designs lies a spectrum of hybrid approaches. These designs extend crossover trials to 3–4 periods, allowing some within-person replication while maintaining feasibility. For example, a 4-path randomization (ABAB, ABBA, BAAB, BABA) provides two treatment contrasts per person—insufficient for robust individual effect estimation but enough to partially estimate heterogeneity (Senn, 2002). Hybrid designs represent a practical compromise when full N-of-1 density is infeasible but pure crossover replication is inadequate.

# Core Differences Between Designs

## Purpose and Estimands

The essential difference lies in the estimands, not the analytic framework.

- **Classic crossover**: population mean treatment effect (Mills et al., 2009).
- **Aggregated N-of-1**: individual treatment effects plus heterogeneity (Lillie et al., 2011).

## Replication Structure

Replication determines what can be estimated.

- Crossover trials provide limited within-person replication—often only one treatment contrast—making random slopes for treatment unidentifiable (Brown, 1980).
- Aggregated N-of-1 trials provide substantial within-person replication, enabling estimation of random slopes and heterogeneity.

## Homogeneity vs Heterogeneity

Crossover designs traditionally assume minimal heterogeneity (Senn, 2002). Aggregated N-of-1 designs assume and model heterogeneity directly (Punja et al., 2016).

## Carryover Effects

Carryover—the persistence of treatment effects into subsequent periods—is handled fundamentally differently across designs:

- **Classic crossover**: Carryover is typically tested and assumed negligible. If present, it confounds period and treatment effects, potentially invalidating the design. Washout periods are employed to eliminate carryover, and statistical tests for carryover are often underpowered (Dwan et al., 2019; Senn, 2002).

- **Aggregated N-of-1**: Multiple treatment cycles enable explicit modeling of carryover as a parameter. Carryover can be incorporated as a fixed effect based on prior-period treatment, with magnitude determined by pharmacokinetic half-life. This transforms carryover from a nuisance to an estimable quantity.

- **Hybrid designs**: With 3–4 periods, some carryover estimation becomes possible, though less robust than in full N-of-1 designs.

The key distinction: crossover designs require carryover to be absent, while aggregated N-of-1 designs can accommodate and estimate it.

## Biomarker-Treatment Interactions

A critical extension beyond average treatment effects is the estimation of treatment effect modification by baseline or time-varying biomarkers. This addresses the personalized medicine question: "For whom does this treatment work best?"

- **Classic crossover**: Can include baseline biomarker × treatment interactions as fixed effects. However, with limited within-person replication, only population-level effect modification is estimable. The model answers: "Do patients with high biomarker values respond differently on average?"

- **Aggregated N-of-1**: Dense within-person data enables estimation of both:
  1. Population-level biomarker × treatment interactions
  2. Individual-specific biomarker × treatment slopes (random slopes)

  This allows the model to answer: "How does this specific patient's biomarker value predict their treatment response?" Time-varying biomarkers can be incorporated, linking within-person biomarker fluctuations to within-person treatment response variation.

- **Hybrid designs**: Can estimate population-level biomarker × treatment interactions with some precision, but individual-specific interaction terms remain difficult to identify.

The inclusion of biomarker interactions shifts the estimand from "Does treatment work?" to "For whom and under what conditions does treatment work?"—a fundamentally different scientific question that aggregated N-of-1 designs are uniquely positioned to answer.

# Mixed-Model Specification

## Classic Crossover Mixed Model

A typical model (where $i$ indexes participants, $t$ indexes periods):

$$Y_{it} = \beta_0 + \beta_{treat} \times Treat_{it} + \beta_{period} \times Period_t + \beta_{bm} \times BM_i + \beta_{int} \times (Treat_{it} \times BM_i) + u_i + \varepsilon_{it}$$

- Random intercept only ($u_i$)
- Treatment effect treated as fixed (Araujo & Julious, 2014)
- Biomarker × treatment interaction estimable at population level
- Random slopes for treatment generally not identifiable due to insufficient replication (Brown, 1980)

## Aggregated N-of-1 Hierarchical Mixed Model

$$Y_{it} = \beta_0 + (\beta_{treat} + u_{i,treat}) \times Treat_{it} + \beta_{period} \times Period_t + \beta_{bm} \times BM_{it} + (\beta_{int} + u_{i,int}) \times (Treat_{it} \times BM_{it}) + u_i + \varepsilon_{it}$$

- Random intercept ($u_i$), random slope for treatment ($u_{i,treat}$), and optionally random slope for biomarker interaction ($u_{i,int}$)
- Individual treatment effect = $\beta_{treat} + u_{i,treat}$
- Individual biomarker interaction = $\beta_{int} + u_{i,int}$
- Heterogeneity quantified via $Var(u_{i,treat})$ and $Var(u_{i,int})$
- Time-varying biomarkers ($BM_{it}$) can link within-person biomarker changes to within-person treatment response

## Hybrid Design Mixed Model

$$Y_{it} = \beta_0 + \beta_{treat} \times Treat_{it} + \beta_{period} \times Period_t + \beta_{bm} \times BM_i + \beta_{int} \times (Treat_{it} \times BM_i) + \beta_{carry} \times Carry_{it} + u_i + \varepsilon_{it}$$

- Random intercept with fixed effects for treatment, biomarker interaction, and carryover
- With 3–4 periods, limited random slope estimation may be attempted but often yields singular fits
- Carryover explicitly modeled as fixed effect based on prior-period treatment

## Why the Models Cannot Be the Same

Even though both use LMMs, the models differ because of:

- Different estimands
- Different random-effect structures
- Different identifiability conditions
- Different inferential goals (Senn, 2002; Zucker et al., 2010)

# Example: A PTSD (CAPS) Trial Designed as Either Crossover or Aggregated N-of-1

To illustrate the design differences, consider a hypothetical new fast-acting pharmacologic agent for reducing PTSD symptoms, measured using CAPS-5.

## Clinical Assumptions

- Onset: 24–48 hours
- Washout: 48–72 hours
- Outcome measurement: daily CAPS or EMA-based PTSD symptom indices
- Condition: chronic, variable symptoms, suitable for repeated within-person comparisons

## Option 1: Classic 3-Period Crossover Design

**Design:**

- Sequence ABA or BAB
- Treatment periods: 3 weeks each (3 periods total)
- Washout: 1 week between periods
- N = approximately 40 participants
- Each participant receives treatment 3 times (either 2A+1B or 1A+2B)

**Strengths:**

- Well-aligned with regulatory expectations
- Simple interpretation of average treatment effect
- More within-person replication than 2-period design

**Limitations:**

- Limited treatment contrasts per person (not fully balanced within individual)
- Cannot robustly estimate individual treatment effects
- Less suitable if heterogeneity is clinically important (Dwan et al., 2019)

**Mixed Model:**

- Random intercept only
- Fixed treatment effect
- Period and sequence as fixed effects

## Option 2: Aggregated N-of-1 Trial

**Design:**

- Each participant undergoes 3 cycles of active vs placebo: ABABAB (3 on-treatment, 3 off-treatment periods)
- Treatment periods: 1 week active, 1 week placebo
- Washout: same-week washout built in due to rapid clearance
- CAPS measured daily using EMA or twice weekly in clinic
- N = 25 participants (fewer needed due to dense data)
- Each participant receives treatment 3 times (balanced: 3A + 3B)

### Why Fewer Participants Suffice

The N-of-1 design achieves adequate power with fewer participants because:

1. **Increased effective sample size**: Each participant contributes multiple treatment contrasts (3 cycles = 3 balanced contrasts vs unbalanced contrasts in crossover). With 25 participants × 3 cycles, the effective number of treatment comparisons approaches 75.

2. **Reduced within-person variance**: Dense repeated measurements within periods average out measurement error and day-to-day fluctuations.

3. **Partial pooling**: Hierarchical models borrow strength across participants. Participants with fewer observations or more noise are shrunk toward the population mean, improving precision for both individual and population estimates (Zucker et al., 2010).

4. **Direct estimation target**: If the goal is individual treatment effects (not just population average), N-of-1 provides the data structure required—crossover designs cannot achieve this regardless of sample size.

**Strengths:**

- Estimates individual treatment effects
- Captures treatment-effect heterogeneity
- Estimates biomarker × treatment interactions at individual level
- Can explicitly model carryover effects
- Partially pooled model improves precision (Lillie et al., 2011; Zucker et al., 2010)

**Limitations:**

- Higher participant burden
- Requires stable condition and rapid washout
- More complex data management

**Mixed Model:**

- Random intercept and random slope for treatment
- Biomarker × treatment interaction (fixed or random)
- Carryover effect (fixed)
- Individual effects reported alongside pooled effect
- Heterogeneity explicitly estimated

## Interpretation Differences

| Question | Crossover | Hybrid | Aggregated N-of-1 |
|----------|-----------|--------|-------------------|
| Does the drug work on average? | Yes | Yes | Yes |
| Does the drug work for this individual? | No | Limited | Yes |
| Is treatment effect heterogeneous? | Rarely estimable | Partially | Yes |
| Does biomarker predict response (population)? | Yes | Yes | Yes |
| Does biomarker predict response (individual)? | No | No | Yes |
| Can carryover be estimated? | No (assumed absent) | Partially | Yes |
| Does each person have replicated comparisons? | Limited (3 periods) | Limited (3-4) | Yes (3+ balanced cycles) |

## Choosing Between the Designs for a PTSD Trial

- If the goal is regulatory approval or demonstration of a population-average effect → Crossover (Dwan et al., 2019).
- If the goal is to understand who responds, optimize personalized treatment, or examine heterogeneity → Aggregated N-of-1 (Lillie et al., 2011; Punja et al., 2016).
- If measurement is frequent and the drug acts quickly → N-of-1 is advantageous.
- If measurement is sporadic or drug has slow dynamics → Crossover preferred.

# Alternative Analyses for Testing Biomarker × Treatment Interactions

While mixed-effects models provide the most statistically efficient analysis of biomarker × treatment interactions, they can obscure intuition about what drives statistical power. Alternative approaches based on summary statistics offer simpler, more interpretable heuristics for understanding when interactions are detectable and what data patterns indicate their presence.

## The Core Insight: Interaction as Correlation

Testing a biomarker × treatment interaction is mathematically equivalent to asking: **Does the individual treatment effect correlate with the biomarker?**

For each subject $i$, compute the treatment effect as the difference in mean outcomes:
$$\Delta_i = \bar{Y}_{i,active} - \bar{Y}_{i,placebo}$$

The interaction test then reduces to asking whether $\Delta_i$ varies systematically with $BM_i$. This can be assessed through:

1. **Pearson correlation** between $\Delta_i$ and $BM_i$
2. **Simple linear regression** of $\Delta_i$ on $BM_i$
3. **ANOVA** comparing mean $\Delta_i$ across biomarker groups

These approaches yield nearly equivalent p-values but provide different effect size metrics that aid interpretation.

## Signal-to-Noise Framework for Power

Power to detect the interaction depends on a simple signal-to-noise ratio:

$$\text{SNR} = \frac{|\beta_{int}| \cdot \sigma_{BM}}{\sigma_\Delta}$$

This ratio equals the expected correlation $r$ between biomarker and treatment response. The components are:

- **Signal** ($|\beta_{int}| \cdot \sigma_{BM}$): The interaction magnitude times biomarker spread. Larger interactions and greater biomarker variability increase the signal.

- **Noise** ($\sigma_\Delta$): The standard deviation of individual treatment effects. This includes:
  - Measurement error: $\sqrt{2\sigma^2_\varepsilon / n_{obs}}$ where $n_{obs}$ is observations per subject per treatment
  - Treatment effect heterogeneity: $\sigma_{treat}$ (individual differences not explained by biomarker)

## Implications for Study Design

This framework reveals why aggregated N-of-1 designs have superior power for detecting interactions:

1. **Dense measurements reduce $\sigma_\Delta$**: With many observations per subject, the treatment effect estimate has lower variance. In the N-of-1 simulation (21 observations per treatment), measurement error contributes minimally to $\sigma_\Delta$.

2. **Unexplained heterogeneity is the enemy**: Individual differences in treatment response that are *not* predicted by the biomarker ($\sigma_{treat}$) increase noise without adding signal. This heterogeneity cannot be reduced by more observations—it requires either larger samples or better predictors.

3. **Biomarker spread provides leverage**: Homogeneous biomarker values yield no ability to detect interactions regardless of sample size. Consider enrichment designs that ensure variability in the biomarker of interest.

## Power Rules of Thumb

Using the correlation framework, standard power calculations apply:

| Expected $r$ | Required N (80% power) | Interpretation |
|--------------|------------------------|----------------|
| 0.10 | >750 | Rarely practical |
| 0.20 | ~200 | Large study needed |
| 0.30 | ~85 | Moderate study |
| 0.40 | ~45 | Feasible |
| 0.50 | ~30 | Small study sufficient |

For a given design, compute the expected $r$ from model parameters to determine required sample size.

## Pattern Recognition in Data

Detectable interactions manifest as:

- **Non-parallel lines** in treatment × biomarker interaction plots
- **Significant correlation** between biomarker and per-subject treatment effect
- **Monotonic trend** in mean treatment effect across biomarker tertiles
- **Positive $R^2$** when regressing treatment effect on biomarker

The summary statistic approach makes these patterns directly visible and interpretable, complementing the more complex mixed-model output.

## Comparison with Mixed-Effects Models

The summary statistic approach:

- **Advantages**: Simpler computation, transparent power calculations, direct visualization of interaction patterns
- **Disadvantages**: Ignores within-subject correlation structure, potentially less efficient

In practice, the two approaches often yield similar power, particularly when within-subject correlations are modest. The summary statistic approach serves as a valuable complement for building intuition and planning studies, while mixed models remain preferred for final inference.

# Conclusion

Although classic crossover and aggregated N-of-1 designs can both be analyzed using mixed-effects models, the correct models differ fundamentally. Crossover trials typically feature random-intercept models targeting a population-level treatment effect with minimal within-person replication. Aggregated N-of-1 designs feature hierarchical mixed models with random slopes for treatment, enabling estimation of individual effects and treatment heterogeneity. Hybrid designs occupy a middle ground, extending crossover to 3–4 periods for some heterogeneity estimation.

A critical extension is biomarker × treatment interactions. All three designs can estimate population-level effect modification (does biomarker predict response on average?), but only aggregated N-of-1 designs provide sufficient within-person replication to estimate individual-specific biomarker interactions. This shifts the estimand from "Does treatment work?" to "For whom and under what conditions does treatment work?"—the fundamental question of personalized medicine.

Similarly, carryover effects—typically a nuisance to be eliminated in crossover designs—can be explicitly modeled and estimated in aggregated N-of-1 designs due to multiple treatment cycles.

The choice of design should be guided by:

- **Scientific aims**: Population average vs individual-level inference
- **Estimand**: Average treatment effect vs biomarker-stratified effects vs individual effects
- **Pharmacologic properties**: Onset, washout, and carryover characteristics
- **Feasibility**: Participant burden, measurement frequency, study duration

When the goal is regulatory approval of a population-average effect, crossover designs remain appropriate. When the goal is precision medicine—identifying who responds and why—aggregated N-of-1 designs are uniquely positioned to answer these questions.

# References

- Araujo, A., & Julious, S. A. (2014). Understanding the assumptions of crossover trials. *Pharmaceutical Statistics*, 13(6), 341–350.
- Brown, H. (1980). The analysis of variance and covariance in crossover trials. *Biometrics*, 36(1), 69–79.
- Deaton, A., & Cartwright, N. (2018). Understanding and misunderstanding randomized controlled trials. *Social Science & Medicine*, 210, 2–21.
- Dwan, K., Li, T., Altman, D. G., & Elbourne, D. (2019). CONSORT 2010 statement: extension to randomised crossover trials. *BMJ*, 366, l4378.
- Guyatt, G. H., et al. (2000). The N-of-1 randomized controlled trial: Clinical usefulness. *Annals of Internal Medicine*, 112(4), 293–299.
- Mills, E. J., Chan, A. W., Wu, P., Vail, A., Guyatt, G. H., & Altman, D. G. (2009). Design, analysis, and presentation of crossover trials. *Trials*, 10, 27.
- Lillie, E. O., et al. (2011). The n-of-1 clinical trial: The ultimate strategy for individualizing medicine? *Personalized Medicine*, 8(2), 161–173.
- Punja, S., et al. (2016). N-of-1 trials for precision medicine: A systematic review. *Journal of Clinical Epidemiology*, 76, 1–13.
- Schmid, C. H., et al. (2013). Effect of statin therapy on muscle symptoms: An individual patient data meta-analysis. *JAMA Internal Medicine*, 173(16), 1–9.
- Senn, S. (2002). *Cross-over Trials in Clinical Research* (2nd ed.). Wiley.
- Zucker, D. R., Ruthazer, R., & Schmid, C. H. (2010). Individual (N-of-1) trials can be combined to give population comparative treatment effect estimates: Methodologic considerations. *Journal of Clinical Epidemiology*, 63(12), 1312–1323.

\newpage

# Appendix: R Code for Simulation and Analysis

Below are example R code chunks to simulate datasets for a classic crossover and an aggregated N-of-1 design, and to fit appropriate mixed-effects models. The code uses `lme4` for frequentist mixed models, `nlme` for correlation structures if desired, and `brms` for a Bayesian hierarchical alternative.

```{r load-packages}
library(tidyverse)
library(lme4)
library(lmerTest)  # Provides p-values for lmer models
library(nlme)
library(emmeans)
# library(brms)  # Uncomment if using Bayesian models
```

## Simulate a Classic 3-Period Crossover Dataset with Biomarker

```{r simulate-crossover}
set.seed(2025)

# Parameters
n_subj <- 40
periods <- 3

# True effects
mu <- 20                    # baseline mean CAPS score
beta_treat <- -4            # average treatment effect (reduction)
beta_bm <- 2                # biomarker main effect
beta_int <- -1.5            # biomarker x treatment interaction
beta_period <- 0.5          # period effect
sigma_subj <- 6             # between-subject SD
sigma_resid <- 8            # residual SD

# Create subject-level intercepts and baseline biomarker
subj_df <- tibble(
  subject = 1:n_subj,
  u = rnorm(n_subj, 0, sigma_subj),
  bm = rnorm(n_subj, 0, 1)
)

# Assign half to sequence ABA and half to BAB
subj_df <- subj_df %>%
  mutate(sequence = rep(c("ABA", "BAB"), length.out = n_subj))

# Expand to periods
crossover <- subj_df %>%
  group_by(subject) %>%
  reframe(period = 1:periods, u = u, bm = bm, sequence = sequence) %>%
  mutate(
    treatment = case_when(
      sequence == "ABA" & period == 1 ~ "A",
      sequence == "ABA" & period == 2 ~ "B",
      sequence == "ABA" & period == 3 ~ "A",
      sequence == "BAB" & period == 1 ~ "B",
      sequence == "BAB" & period == 2 ~ "A",
      sequence == "BAB" & period == 3 ~ "B"
    ),
    trt_indicator = if_else(treatment == "B", 1, 0)
  )

# Simulate outcome with biomarker interaction
crossover <- crossover %>%
  mutate(
    Y = mu + u +
      beta_period * period +
      beta_treat * trt_indicator +
      beta_bm * bm +
      beta_int * trt_indicator * bm +
      rnorm(n(), 0, sigma_resid)
  )

# Quick glance
head(crossover)
```

## Fit the Classic Crossover Mixed Model with Biomarker Interaction

```{r fit-crossover}
# lmer with random intercept and biomarker x treatment interaction
m_crossover <- lmer(
  Y ~ trt_indicator * bm + factor(period) + (1 | subject),
  data = crossover
)
summary(m_crossover)

# Estimated average treatment effect (at mean biomarker = 0)
fixef(m_crossover)["trt_indicator"]

# Estimated biomarker x treatment interaction (population-level)
fixef(m_crossover)["trt_indicator:bm"]

# Treatment effect at different biomarker levels
emmeans(m_crossover, ~ trt_indicator | bm, at = list(bm = c(-1, 0, 1)))
```

**Interpretation**: Can estimate population-level effect modification, but cannot estimate individual-specific interaction terms.

## Simulate an Aggregated N-of-1 Dataset with Biomarker and Carryover

```{r simulate-nof1}
set.seed(2025)

n_subj <- 25
cycles <- 6
obs_per_period <- 7

# True effects
mu <- 20
beta_treat_pop <- -4
beta_bm <- 2
beta_int_pop <- -1.5
beta_carry <- 1.5

sigma_subj <- 6
sigma_treat_sd <- 3
sigma_int_sd <- 0.8
sigma_resid <- 5

# Create subject-level random effects
subj <- tibble(
  subject = 1:n_subj,
  u = rnorm(n_subj, 0, sigma_subj),
  u_trt = rnorm(n_subj, 0, sigma_treat_sd),
  u_int = rnorm(n_subj, 0, sigma_int_sd),
  bm_baseline = rnorm(n_subj, 0, 1)
)

# Build periods alternating A/B starting at random
nof1 <- subj %>%
  crossing(period = 1:cycles) %>%
  group_by(subject) %>%
  mutate(order_start = first(sample(c(0, 1), 1))) %>%
  ungroup() %>%
  mutate(trt_indicator = (order_start + period) %% 2)

# Expand to daily observations within each period
nof1 <- nof1 %>%
  crossing(day = 1:obs_per_period) %>%
  arrange(subject, period, day)

# Add time-varying biomarker
nof1 <- nof1 %>%
  mutate(bm = bm_baseline + rnorm(n(), 0, 0.3))

# Add carryover effect
nof1 <- nof1 %>%
  group_by(subject) %>%
  mutate(
    prior_trt = lag(trt_indicator, default = 0),
    carryover = if_else(period > 1 & day <= 2, prior_trt, 0)
  ) %>%
  ungroup()

# Simulate outcomes
nof1 <- nof1 %>%
  mutate(
    Y = mu + u +
      (beta_treat_pop + u_trt) * trt_indicator +
      beta_bm * bm +
      (beta_int_pop + u_int) * trt_indicator * bm +
      beta_carry * carryover +
      rnorm(n(), 0, sigma_resid)
  )

# Inspect
nof1 %>%
  group_by(subject) %>%
  summarise(n_obs = n(), n_periods = n_distinct(period)) %>%
  head()
```

## Fit Aggregated N-of-1 Hierarchical Mixed Model with Biomarker Interaction

```{r fit-nof1}
# Random intercept + random slope for treatment + biomarker interaction + carryover
m_nof1 <- lmer(
  Y ~ trt_indicator * bm + carryover + (1 + trt_indicator | subject),
  data = nof1,
  REML = TRUE
)
summary(m_nof1)

# Extract fixed (population) effects
fixef(m_nof1)

# Population treatment effect (at mean biomarker = 0)
fixef(m_nof1)["trt_indicator"]

# Population biomarker x treatment interaction
fixef(m_nof1)["trt_indicator:bm"]

# Carryover effect
fixef(m_nof1)["carryover"]

# Extract subject-specific treatment effects (BLUPs)
subj_trt_effects <- ranef(m_nof1)$subject[["trt_indicator"]] +
  fixef(m_nof1)["trt_indicator"]
head(subj_trt_effects)
```

### Advanced Model with Random Biomarker Interaction

```{r fit-nof1-advanced, eval=FALSE}
# This estimates individual-specific biomarker x treatment interactions
# May need more data or regularization for convergence
m_nof1_full <- lmer(
  Y ~ trt_indicator * bm + carryover +
    (1 + trt_indicator + trt_indicator:bm | subject),
  data = nof1,
  REML = TRUE,
  control = lmerControl(optimizer = "bobyqa")
)
summary(m_nof1_full)
```

## Diagnostics and Visualization

```{r viz-individual-effects, fig.cap="Distribution of individual treatment effects"}
# Plot individual subject treatment effects
subj_effects <- ranef(m_nof1)$subject %>%
  as.data.frame() %>%
  rownames_to_column(var = "subject") %>%
  mutate(
    subject = as.integer(subject),
    subj_trt = trt_indicator + fixef(m_nof1)["trt_indicator"]
  )

ggplot(subj_effects, aes(x = subj_trt)) +
  geom_histogram(binwidth = 0.5, fill = "steelblue", color = "white") +
  geom_vline(
    xintercept = fixef(m_nof1)["trt_indicator"],
    linetype = "dashed",
    color = "red"
  ) +
  labs(
    title = "Distribution of Individual Treatment Effects (BLUPs)",
    subtitle = "Red line = population average effect",
    x = "Individual treatment effect (CAPS change)",
    y = "Count"
  ) +
  theme_minimal()
```

```{r viz-interaction, fig.cap="Biomarker by treatment interaction"}
# Plot biomarker x treatment interaction
bm_range <- seq(-2, 2, by = 0.1)
interaction_df <- tibble(
  bm = bm_range,
  trt_effect = fixef(m_nof1)["trt_indicator"] +
    fixef(m_nof1)["trt_indicator:bm"] * bm_range
)

ggplot(interaction_df, aes(x = bm, y = trt_effect)) +
  geom_line(linewidth = 1.2, color = "darkgreen") +
  geom_hline(yintercept = 0, linetype = "dotted") +
  labs(
    title = "Biomarker × Treatment Interaction",
    subtitle = "Treatment effect as function of biomarker level",
    x = "Biomarker (standardized)",
    y = "Treatment effect (CAPS change)"
  ) +
  theme_minimal()
```

```{r viz-trajectories, fig.cap="Individual patient trajectories"}
# Observed trajectories for sample subjects
sample_subj <- sample(unique(nof1$subject), 6)

nof1 %>%
  filter(subject %in% sample_subj) %>%
  mutate(
    time = (period - 1) * obs_per_period + day,
    trt = if_else(trt_indicator == 1, "Active", "Placebo")
  ) %>%
  ggplot(aes(x = time, y = Y, color = trt)) +
  geom_line(alpha = 0.7) +
  geom_point(size = 0.8) +
  facet_wrap(~subject, scales = "free_y") +
  labs(
    title = "Individual Patient Trajectories",
    x = "Day",
    y = "CAPS score",
    color = "Treatment"
  ) +
  theme_minimal()
```

## Notes on Extensions and Real-Data Considerations

- For real CAPS outcomes measured daily, expand the simulation to include within-period autocorrelation (e.g., AR(1)), measurement error, and missingness. Use `nlme::lme` or specify correlation structures for autocorrelation.

- If carryover is suspected, consider adding period-by-treatment interaction terms or explicitly modeling carryover terms; tests for carryover should be planned but interpreted cautiously (Dwan et al., 2019).

- In the aggregated N-of-1 context, Bayesian hierarchical models (e.g., `brms`) allow flexible priors and full posterior inference for individual effects (Zucker et al., 2010).

- For regulatory-facing analyses, prespecify the primary estimand (population mean vs individual responder analysis), multiplicity handling, and sensitivity analyses for missing data and carryover.

## Alternative Analyses: Summary Statistic Approaches

These methods complement the mixed-model analysis by providing interpretable heuristics for understanding interaction patterns.

### Strategy 1: Summary Statistic Regression

```{r summary-stat-regression}
# Compute per-subject treatment effects from the N-of-1 data
subj_summary <- nof1 %>%
  group_by(subject, trt_indicator) %>%
  summarise(mean_Y = mean(Y), .groups = "drop") %>%
  pivot_wider(names_from = trt_indicator, values_from = mean_Y,
              names_prefix = "trt_") %>%
  mutate(delta = trt_1 - trt_0)  # Active - Placebo

# Merge with baseline biomarker
subj_summary <- nof1 %>%
  distinct(subject, bm_baseline) %>%
  right_join(subj_summary, by = "subject")

# Simple linear regression of treatment effect on biomarker
reg_summary <- lm(delta ~ bm_baseline, data = subj_summary)
summary(reg_summary)

# The slope directly estimates the interaction
coef(reg_summary)["bm_baseline"]
```

### Strategy 2: Correlation Test

```{r correlation-test}
# Pearson correlation between biomarker and treatment effect
cor_result <- cor.test(subj_summary$bm_baseline, subj_summary$delta)
cor_result

# Effect size: r ≈ 0.1 small, r ≈ 0.3 medium, r ≈ 0.5 large
```

### Strategy 3: ANOVA with Biomarker Tertiles

```{r anova-tertiles}
# Discretize biomarker into tertiles
subj_summary <- subj_summary %>%
  mutate(
    bm_tertile = cut(
      bm_baseline,
      breaks = quantile(bm_baseline, c(0, 1/3, 2/3, 1)),
      labels = c("Low", "Medium", "High"),
      include.lowest = TRUE
    )
  )

# One-way ANOVA
anova_result <- anova(lm(delta ~ bm_tertile, data = subj_summary))
anova_result

# Effect size: eta-squared
eta_sq <- anova_result["bm_tertile", "Sum Sq"] / sum(anova_result[, "Sum Sq"])
cat("Eta-squared:", round(eta_sq, 3), "\n")

# Cell means
subj_summary %>%
  group_by(bm_tertile) %>%
  summarise(
    n = n(),
    mean_delta = mean(delta),
    sd_delta = sd(delta),
    .groups = "drop"
  )
```

### Comparing Methods

```{r compare-methods}
# Extract p-value from lmer model (requires lmerTest)
lmer_coefs <- coef(summary(m_nof1))
lmer_pval <- lmer_coefs["trt_indicator:bm", "Pr(>|t|)"]

# Compile results
comparison <- tibble(
  Method = c("Mixed Model", "Summary Regression", "Correlation", "ANOVA"),
  Estimate = c(
    fixef(m_nof1)["trt_indicator:bm"],
    coef(reg_summary)["bm_baseline"],
    cor_result$estimate,
    eta_sq
  ),
  P_value = c(
    lmer_pval,
    summary(reg_summary)$coefficients["bm_baseline", "Pr(>|t|)"],
    cor_result$p.value,
    anova_result["bm_tertile", "Pr(>F)"]
  )
)

comparison %>%
  mutate(Estimate = round(Estimate, 3),
         P_value = format.pval(P_value, digits = 3))
```

### Visualizing Interaction Patterns

```{r viz-interaction-pattern, fig.cap="Treatment effect by biomarker group"}
ggplot(subj_summary, aes(x = bm_tertile, y = delta, fill = bm_tertile)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_fill_brewer(palette = "Blues") +
  labs(
    title = "Treatment Effect by Biomarker Group",
    subtitle = "Trend indicates biomarker × treatment interaction",
    x = "Biomarker Tertile",
    y = "Individual Treatment Effect (Δ)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r viz-scatter-interaction, fig.cap="Biomarker vs treatment effect"}
ggplot(subj_summary, aes(x = bm_baseline, y = delta)) +
  geom_point(alpha = 0.7, size = 2) +
  geom_smooth(method = "lm", se = TRUE, color = "darkblue") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Biomarker vs Individual Treatment Effect",
    subtitle = paste("r =", round(cor_result$estimate, 2)),
    x = "Baseline Biomarker",
    y = "Individual Treatment Effect (Δ)"
  ) +
  theme_minimal()
```

## Analytic Power Calculations

Closed-form power formulas help plan studies and understand parameter impacts.

### Power Function for Correlation

```{r power-function}
power_correlation <- function(r, n, alpha = 0.05) {
  ncp <- abs(r) * sqrt(n - 2) / sqrt(1 - r^2)
  t_crit <- qt(1 - alpha/2, n - 2)
  power <- pt(t_crit, n - 2, ncp, lower.tail = FALSE) +
           pt(-t_crit, n - 2, ncp, lower.tail = TRUE)
  return(power)
}

# Power table
power_table <- expand_grid(
  r = c(0.1, 0.2, 0.3, 0.4, 0.5),
  n = c(20, 40, 70, 100, 150)
) %>%
  mutate(power = map2_dbl(r, n, power_correlation))

power_table %>%
  pivot_wider(names_from = n, values_from = power, names_prefix = "N=") %>%
  mutate(across(starts_with("N="), ~round(., 2)))
```

```{r power-curves, fig.cap="Power curves for interaction detection"}
ggplot(power_table, aes(x = n, y = power, color = factor(r))) +
  geom_line(linewidth = 1) +
  geom_point() +
  geom_hline(yintercept = 0.8, linetype = "dashed", alpha = 0.5) +
  scale_color_viridis_d(option = "plasma", end = 0.8) +
  labs(
    title = "Power to Detect Biomarker × Treatment Interaction",
    x = "Number of Subjects",
    y = "Power",
    color = "Effect Size (r)"
  ) +
  theme_minimal()
```

### Computing Expected Effect Size from Parameters

```{r expected-effect-size}
compute_expected_r <- function(beta_int, bm_sd, sigma_resid,
                                obs_per_trt, sigma_treat_sd = 0) {
  var_delta <- 2 * sigma_resid^2 / obs_per_trt + sigma_treat_sd^2
  r <- beta_int * bm_sd / sqrt(var_delta)
  return(r)
}

# For our simulation:
expected_r <- compute_expected_r(
  beta_int = beta_int_pop,
  bm_sd = 1,
  sigma_resid = sigma_resid,
  obs_per_trt = cycles * obs_per_period / 2,
  sigma_treat_sd = sigma_treat_sd
)

cat("Expected r:", round(expected_r, 3), "\n")
cat("Power (N=25):", round(power_correlation(expected_r, n_subj), 3), "\n")
```

### Power Grid Across Parameters

```{r power-grid, fig.cap="Power across design parameters"}
power_grid <- expand_grid(
  n_subj = c(20, 40, 70, 100),
  beta_int = c(-0.5, -1.0, -1.5, -2.0),
  obs_per_trt = c(3, 7, 21),
  sigma_treat_sd = c(0, 3)
) %>%
  mutate(
    bm_sd = 1,
    sigma_resid = 5,
    expected_r = compute_expected_r(beta_int, bm_sd, sigma_resid,
                                     obs_per_trt, sigma_treat_sd),
    power = map2_dbl(abs(expected_r), n_subj, power_correlation)
  )

ggplot(power_grid, aes(x = n_subj, y = power,
                        color = factor(beta_int),
                        linetype = factor(sigma_treat_sd))) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 1.5) +
  geom_hline(yintercept = 0.8, linetype = "dashed", alpha = 0.3) +
  facet_wrap(~paste("Obs/trt =", obs_per_trt)) +
  scale_color_viridis_d(option = "plasma", end = 0.85) +
  labs(
    title = "Power Across Design Parameters",
    x = "Number of Subjects",
    y = "Power",
    color = "β_int",
    linetype = "σ_treat"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```
